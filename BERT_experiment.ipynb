{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT experiments visualisation notebook\n",
    "This notebook is to learn how to use BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even though I will not use \"text\" in this experiment as we focus on \"word\", it would be useful to see how BERT works, how we can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"This is a exmpale text.\"\n",
    "marked_text = \"[CLS] \" + input_text + \" [SEP]\"\n",
    "\n",
    "# Tokenize\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print(tokenized_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print(\"{:<12} {:>6,}\".format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment ID\n",
    "segments_ids = [0] * len(tokenized_text)\n",
    "print(segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to tensor\n",
    "tokens_ts = torch.tensor([indexed_tokens])\n",
    "segments_ts = torch.tensor([segments_ids])\n",
    "\n",
    "# load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict hidden states\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_ts, segments_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. interpreting the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of layers: {}\".format(len(encoded_layers)))\n",
    "print(\"Number of batches: {}\".format(len(encoded_layers[0])))  # number of sentences\n",
    "print(\"Number of tokens: {}\".format(len(encoded_layers[0][0])))\n",
    "print(\"Number of hidden units: {}\".format(len(encoded_layers[0][0][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex. the 5th token in the sentence from layer 5\n",
    "t_i = 5\n",
    "l_i = 5\n",
    "vec = encoded_layers[l_i][0][t_i]  # dim = [layers, batchs, tokens, features]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(vec, bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each of 12 layers has tensor [batchs, tokens, features]\n",
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard batch dimension as we don't need it\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute \"layers\" and \"tokens\" to make them [tokens, layers, features]\n",
    "token_embeddings = token_embeddings.permute(1, 0, 2)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. creating word_vec from hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex. concatenate the last four layers\n",
    "# vector will have dimension 4 * 768 = 3072\n",
    "\n",
    "token_vecs_cat = []\n",
    "\n",
    "for token in token_embeddings:\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "    \n",
    "print(\"the size of word_vec dimension: {}\".format(len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex. summing the last four layers\n",
    "# vector will have dimension 768\n",
    "\n",
    "token_vecs_sum = []\n",
    "\n",
    "for token in token_embeddings:\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print(\"the size of word_vec dimension: {}\".format(len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
